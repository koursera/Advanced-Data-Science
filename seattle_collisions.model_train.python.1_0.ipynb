{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle Collisions - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers model training focused on FB Prophet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "from fbprophet.serialize import model_to_json, model_from_json\n",
    "from fbprophet.plot import plot_cross_validation_metric \n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import json\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import types\n",
    "import itertools\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone \n",
    "import time\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Seattle_Collisions_Final.csv', low_memory = False, parse_dates=True, index_col=0)\n",
    "#print('File downloaded')\n",
    "df['INCDTTM'] = pd.to_datetime(df['INCDTTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv('Seattle_Weather_Daily.csv', low_memory = False, parse_dates=True, index_col=0)\n",
    "print('File downloaded')\n",
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_max_temperature(dfw, target_date):\n",
    "    return dfw[(dfw.DATE == target_date)]['TEMPERATURE'].max()\n",
    "\n",
    "def get_day_min_temperature(dfw, target_date):\n",
    "    return dfw[(dfw.DATE == target_date)]['TEMPERATURE'].min()\n",
    "\n",
    "def get_day_total_precipitation(dfw, target_date):\n",
    "    return dfw[(dfw.DATE == target_date)]['PRECIPITATION'].sum()\n",
    "\n",
    "def get_day_solar_azimuth(dfw, target_date):\n",
    "    return dfw[(dfw.DATE == target_date)]['SOLARAZIMUTH'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df[(df.INCDTTM > '2014-12-31') & (df.INCDTTM < '2020-01-01') &\\\n",
    "         (df.HITPARKEDCAR == 0) & (df.PRECIPITATION >= 0) & (df.WEEKDAY.isin([0,1,2,3,4,5,6]))]\n",
    "print(len(dft), len(dft)/(dft.INCDTTM.max() - dft.INCDTTM.min()).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dft.INCDTTM.value_counts().resample('D').sum().to_frame().reset_index()\n",
    "dft.rename({'index':'ds', 'INCDTTM':'y'}, axis=1, inplace=True)\n",
    "dft['rain'] = dft.apply(lambda x: get_day_total_precipitation(df_weather, x.ds.strftime('%Y-%m-%d')), axis=1)\n",
    "dft['temp'] = dft.apply(lambda x: get_day_min_temperature(df_weather, x.ds.strftime('%Y-%m-%d')), axis=1)\n",
    "dft['solar_azimuth'] = dft.apply(lambda x: get_day_solar_azimuth(df_weather, x.ds.strftime('%Y-%m-%d')), axis=1)\n",
    "#dft.y.plot(figsize=(18,3))\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(daily_seasonality=True, weekly_seasonality=True, changepoint_prior_scale=0.5, growth='linear', seasonality_mode='multiplicative') \n",
    "m.add_regressor('rain', mode='multiplicative')\n",
    "m.add_regressor('temp', mode='additive')\n",
    "m.add_regressor('solar_azimuth', mode='multiplicative')\n",
    "m.fit(dft)\n",
    "future = m.make_future_dataframe(periods=10,freq='D',include_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future['rain'] = future.apply(lambda x: get_day_total_precipitation(df_weather, x.ds.strftime('%Y-%m-%d')), axis=1)\n",
    "future['temp'] = future.apply(lambda x: get_day_min_temperature(df_weather, x.ds.strftime('%Y-%m-%d')), axis=1)\n",
    "future['solar_azimuth'] = future.apply(lambda x: get_day_solar_azimuth(df_weather, x.ds.strftime('%Y-%m-%d')), axis=1)\n",
    "future.head(), future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "dft_results = dft.merge(forecast, how='outer', left_on='ds', right_on='ds')\n",
    "dft_results[['ds', 'y', 'yhat', 'yhat_lower', 'yhat_upper', 'trend', 'additive_terms','multiplicative_terms']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dft_results['y'].values\n",
    "y_hat = dft_results['yhat'].values\n",
    "mae = mean_absolute_error(y_true[:-10], y_hat[:-10])\n",
    "print('MAE: %.3f' % mae)\n",
    "rsme = sqrt(mean_squared_error(y_true[:-10], y_hat[:-10]))\n",
    "print('RSME: %.3f' % rsme)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(26,10))\n",
    "plt.plot(y_true, label='Actual')\n",
    "plt.plot(y_hat, label='Predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = m.plot(forecast, figsize=(20,10))\n",
    "for changepoint in m.changepoints:\n",
    "    plt.axvline(changepoint,ls='--', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seattle_collision_model.json', 'w') as fout:\n",
    "    json.dump(model_to_json(m), fout)  # Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet has many tools built-in.  I did not extensively use due to time constraints, a todo to revisit this and improve on what's here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "#https://facebook.github.io/prophet/docs/diagnostics.html\n",
    "#Here we do cross-validation to assess prediction performance on a horizon of 365 days, starting with 730 days of training data in the first \n",
    "#cutoff and then making predictions every 180 days. On this 8 year time series, this corresponds to 11 total forecasts.\n",
    "#df_cv = cross_validation(m, initial='730 days', period='180 days', horizon = '365 days')\n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "    m = Prophet(**params).fit(dft)  # Fit model with given params\n",
    "    df_cv = cross_validation(m, initial='1460 days', period='10 days', horizon='365 days')  #cutoffs=cutoffs, , parallel=\"processes\"\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "print(tuning_results)\n",
    "best_params = all_params[np.argmin(rmses)]\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
